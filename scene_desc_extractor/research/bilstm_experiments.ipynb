{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alexandra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:41:23.147356873Z",
     "start_time": "2024-04-15T15:41:21.151672370Z"
    }
   },
   "id": "a56b1e78bc22443d",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "The get_lstm_features function returns the LSTM’s tag vectors. The function performs all the steps mentioned above for the model.\n",
    "Steps:\n",
    "1) It takes in characters, converts them to embeddings using our character LSTM.\n",
    "2) We concat Character Embeding with embeding word vectors, use this as features that we feed to Bidirectional-LSTM.\n",
    "3) The Bidirectional-LSTM generates outputs based on these set of features.\n",
    "4) The output are passed through a linear layer to convert to tag space."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35cd2a4d1d551682"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "START_TAG = 'B'\n",
    "END_TAG = 'E'\n",
    "NO_ENTITY_TAG = 'O'\n",
    "\n",
    "START_SENTENCE_TOKEN = '[CLS]'\n",
    "SEP_SENTENCE_TOKEN = '[SEP]'\n",
    "PAD_TOKEN = '[PAD]'\n",
    "UNKNOWN_TOKEN = '[UNK]'\n",
    "\n",
    "START_SENTENCE_TOKEN_ID = 101\n",
    "SEP_SENTENCE_TOKEN_ID = 102\n",
    "PAD_TOKEN_ID = 0\n",
    "UNKNOWN_TOKEN_ID = 100\n",
    "\n",
    "SPECIAL_TOKENS = [START_SENTENCE_TOKEN, SEP_SENTENCE_TOKEN, PAD_TOKEN, UNKNOWN_TOKEN]\n",
    "\n",
    "ENTITY_LABELS = {'person': 1, 'place': 2, 'organization': 3, 'object': 4, 'event': 5, \n",
    "                 'time': 6, 'substance': 7, 'animal': 8, 'plant': 9, 'abstract': 10,\n",
    "                 '[CLS]': START_SENTENCE_TOKEN_ID, '[SEP]': SEP_SENTENCE_TOKEN_ID, '[PAD]': PAD_TOKEN_ID}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:41:27.657557626Z",
     "start_time": "2024-04-15T15:41:27.655405333Z"
    }
   },
   "id": "acb2f1e361b92d5e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultiSentenceDataset(Dataset):\n",
    "    def __init__(self, file_dir, labels_dir=None, uncased=True, \n",
    "                 bert_model_name='bert-base-uncased', max_seq_length=512, \n",
    "                 max_token_length=15):\n",
    "        self.file_dir = file_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.uncased = uncased\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_token_length = max_token_length\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.texts_sentences, self.texts_mask, self.sentence_mask, self.labels = self.__read_data()        \n",
    "        self.tokens_ids, self.sentence_lengths, self.word_tokens, self.word_ids = self.__tokenize_sentences()\n",
    "        self.__check_bert_and_labels_word_tokens()\n",
    "        self.chars_dict = self.__get_chars_dict()        \n",
    "        self.chars_vocab_dim = len(self.chars_dict)\n",
    "        self.chars_seq, self.chars_lengths = self.__tokenize_and_pad_characters_per_token()\n",
    "        \n",
    "    \n",
    "    def __check_bert_and_labels_word_tokens(self):\n",
    "        pass\n",
    "        \n",
    "    def __read_data(self):\n",
    "        texts_sentences = []\n",
    "        text_mask = []\n",
    "        sentence_mask = []\n",
    "        labels = []        \n",
    "        text_enumerator = 0        \n",
    "        #for file_name in os.listdir(self.file_dir):\n",
    "        for file_id in range(len(os.listdir(self.file_dir))):\n",
    "            file_name = f'{file_id}.txt'\n",
    "            with open(os.path.join(self.file_dir, file_name), 'r', encoding='utf-8') as file:                \n",
    "                text = file.read()\n",
    "                sentences = sent_tokenize(text)\n",
    "                sentence_mask.extend(range(len(sentences)))\n",
    "                text_mask.extend([text_enumerator]*len(sentences))\n",
    "                texts_sentences.extend(sentences)\n",
    "                \n",
    "                text_enumerator += 1\n",
    "                \n",
    "            if self.labels_dir:                \n",
    "                labels_file_path = os.path.join(self.labels_dir, file_name)\n",
    "                labels.extend(self.__parse_labels(labels_file_path))\n",
    "        return texts_sentences, text_mask, sentence_mask, labels if self.labels_dir else None\n",
    "    \n",
    "    def __parse_labels(self, labels_file_path):\n",
    "        cur_sentence_id = 1\n",
    "        sentence_labels = []\n",
    "        labels = []\n",
    "        with open(labels_file_path, 'r', encoding='utf-8') as file:    \n",
    "            for word in file:\n",
    "                labels_split = word.strip().split('\\t')\n",
    "                new_sentence_id = int(labels_split[0])\n",
    "                word_id = int(labels_split[1])\n",
    "                word = labels_split[2]\n",
    "                entities = []\n",
    "                corefs = []\n",
    "                for i in range(7, len(labels_split)):\n",
    "                    if i%2 > 0:\n",
    "                        corefs.append(labels_split[i])\n",
    "                    else:\n",
    "                        entities.append(labels_split[i])                        \n",
    "                \n",
    "                if new_sentence_id != cur_sentence_id:\n",
    "                    labels.append(sentence_labels)                  \n",
    "                    sentence_labels = []\n",
    "                    cur_sentence_id = new_sentence_id\n",
    "                \n",
    "                sentence_labels.append((word_id, word, entities, corefs))\n",
    "                \n",
    "        labels.append(sentence_labels)                \n",
    "        return labels        \n",
    "        \n",
    "    def __get_words_from_tokens(self, sentence_tokens_ids):\n",
    "        word_tokens = []\n",
    "        word_ids = []\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(sentence_tokens_ids)  \n",
    "        word_id = -1\n",
    "        prev_token_apo = False\n",
    "        for token in tokens:\n",
    "            if token == \"'\":\n",
    "                prev_token_apo = True\n",
    "            else:\n",
    "                if token.startswith(\"##\"):\n",
    "                    word_tokens[-1] += token[2:]\n",
    "                else:\n",
    "                    word_id += 1\n",
    "                    if prev_token_apo:\n",
    "                        word_ids.append(word_id)\n",
    "                        token = \"'\" + token\n",
    "                    word_tokens.append(token)\n",
    "                    prev_token_apo = False\n",
    "                word_ids.append(word_id)            \n",
    "        return word_tokens, word_ids\n",
    "        \n",
    "    def __tokenize_sentences(self):\n",
    "        tokens_ids = []\n",
    "        word_tokens = []\n",
    "        word_ids = []\n",
    "        sentence_lengths = []\n",
    "        for i, sentence in enumerate(self.texts_sentences):  \n",
    "            tokenized_sentence = self.tokenizer(sentence, return_tensors='pt',\n",
    "                                                truncation=False, max_length=self.max_seq_length, \n",
    "                                                return_overflowing_tokens=True)\n",
    "            if len(tokenized_sentence['overflowing_tokens'].squeeze()) > 0:\n",
    "                print(f\"Sentence causing error:\\n{sentence}\\nOverflow Length: {len(tokenized_sentence['overflowing_tokens'].squeeze())} tokens\")\n",
    "            sentence_tokens_ids = tokenized_sentence['input_ids'].squeeze().tolist()            \n",
    "            tokens_ids.append(sentence_tokens_ids)\n",
    "            \n",
    "            sentence_word_tokens, sentence_word_ids = self.__get_words_from_tokens(sentence_tokens_ids)\n",
    "            word_tokens.append(sentence_word_tokens)\n",
    "            word_ids.append(sentence_word_ids)\n",
    "            sentence_lengths.append(len(sentence_word_tokens))\n",
    "            \n",
    "        return tokens_ids, sentence_lengths, word_tokens, word_ids\n",
    "\n",
    "    \n",
    "    def __tokenize_and_pad_characters_per_token(self):\n",
    "        encoded_char_seq = []\n",
    "        chars_lengths = []\n",
    "            \n",
    "        for sentence_index, sentence_length in enumerate(self.sentence_lengths):    \n",
    "            token_char_ids = []\n",
    "            token_lengths = [] \n",
    "            for token_index in range(sentence_length):\n",
    "                token = self.word_tokens[sentence_index][token_index]       \n",
    "                if token in SPECIAL_TOKENS:\n",
    "                    token_char_ids.append(([self.chars_dict[token]]))\n",
    "                else:\n",
    "                    token_char_ids.append(([self.chars_dict[c] for c in token]))         \n",
    "                length = len(token_char_ids[-1])\n",
    "                token_lengths.append(length)   \n",
    "            encoded_char_seq.append(token_char_ids)\n",
    "            chars_lengths.append(token_lengths)\n",
    "        \n",
    "        padded_encoded_char_seq = [[t + [0] * (self.max_token_length - len(t)) for t in s] for s in encoded_char_seq]\n",
    "        return padded_encoded_char_seq, chars_lengths\n",
    "    \n",
    "    \n",
    "    def __get_chars_dict(self):\n",
    "        chars_freq = {START_SENTENCE_TOKEN: len(self.word_tokens), SEP_SENTENCE_TOKEN: len(self.word_tokens), \n",
    "             PAD_TOKEN: 0, UNKNOWN_TOKEN: 0}\n",
    "        \n",
    "        for sentence in self.word_tokens:\n",
    "            for i, token in enumerate(sentence):\n",
    "                if (token == START_SENTENCE_TOKEN) or (token == SEP_SENTENCE_TOKEN):\n",
    "                    continue\n",
    "                if token == PAD_TOKEN:\n",
    "                    break                               \n",
    "                if token == UNKNOWN_TOKEN:\n",
    "                    chars_freq[token] += 1\n",
    "                else: \n",
    "                    for c in token:\n",
    "                        if c in chars_freq:\n",
    "                            chars_freq[c] += 1\n",
    "                        else:\n",
    "                            chars_freq[c] = 0\n",
    "        chars = dict(sorted(chars_freq.items(), key=lambda item: item[1], reverse=True))\n",
    "        del chars[PAD_TOKEN]\n",
    "        chars_vocab = {PAD_TOKEN: 0}\n",
    "        chars_vocab.update(dict((item, i+1) for i, item in enumerate(chars)))\n",
    "        return chars_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens_ids)\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        if self.labels is not None:\n",
    "            pass\n",
    "        else:\n",
    "            return {\n",
    "                    'token_ids': self.tokens_ids[idx], \n",
    "                    'words': self.word_tokens[idx],\n",
    "                    'word_ids': self.word_ids[idx],\n",
    "                    'sentence_length':  self.sentence_lengths[idx],\n",
    "                    'text_mask': self.texts_mask[idx],\n",
    "                    'sentence_mask': self.sentence_mask[idx],\n",
    "                    'word_char_ids': self.chars_seq[idx],\n",
    "                    'word_lengths': self.chars_lengths[idx],\n",
    "                    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:32:01.436379400Z",
     "start_time": "2024-04-15T16:32:01.390229205Z"
    }
   },
   "id": "e021045eb97f6ffb",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# gun reddit files where removed\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "file_dir = 'data_exp/texts'  # Directory containing text files\n",
    "file_dir = '../datasets/gum_parsed/texts/'\n",
    "labels_dir = '../datasets/gum_parsed/labels/'\n",
    "\n",
    "train_dataset = MultiSentenceDataset(file_dir=file_dir, labels_dir= labels_dir, bert_model_name=bert_model_name, uncased=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:44:06.047234355Z",
     "start_time": "2024-04-15T17:44:02.390396943Z"
    }
   },
   "id": "10d850d33b78786a",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "12147"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:44:08.927990469Z",
     "start_time": "2024-04-15T17:44:08.925243310Z"
    }
   },
   "id": "c3395fff1ee88261",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(36, 41)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_id = 3\n",
    "len(train_dataset.labels[sentence_id]), len(train_dataset.word_tokens[sentence_id])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:44:31.480250063Z",
     "start_time": "2024-04-15T17:44:31.472135336Z"
    }
   },
   "id": "1a35cc25f5858cb6",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, '[CLS]', ['O', 'O', 'O', 'O'], ['-100', '-100', '-100', '-100']),\n (1, 'Washington', ['B-place', 'O', 'O', 'O'], ['10', '-100', '-100', '-100']),\n (2, ',', ['I-place', 'O', 'O', 'O'], ['10', '-100', '-100', '-100']),\n (3, 'D.C.', ['L-place', 'U-place', 'O', 'O'], ['10', '11', '-100', '-100']),\n (4, '–', ['O', 'O', 'O', 'O'], ['-100', '-100', '-100', '-100']),\n (5, 'Speaker', ['B-person', 'O', 'O', 'O'], ['2', '-100', '-100', '-100']),\n (6, 'Nancy', ['I-person', 'O', 'O', 'O'], ['2', '-100', '-100', '-100']),\n (7, 'Pelosi', ['L-person', 'O', 'O', 'O'], ['2', '-100', '-100', '-100']),\n (8, 'delivered', ['O', 'O', 'O', 'O'], ['-100', '-100', '-100', '-100']),\n (9, 'remarks', ['B-abstract', 'O', 'O', 'O'], ['12', '-100', '-100', '-100']),\n (10, 'on', ['I-abstract', 'O', 'O', 'O'], ['12', '-100', '-100', '-100']),\n (11,\n  'the',\n  ['I-abstract', 'B-place', 'O', 'O'],\n  ['12', '13', '-100', '-100']),\n (12,\n  'Floor',\n  ['I-abstract', 'I-place', 'O', 'O'],\n  ['12', '13', '-100', '-100']),\n (13, 'of', ['I-abstract', 'I-place', 'O', 'O'], ['12', '13', '-100', '-100']),\n (14,\n  'the',\n  ['I-abstract', 'I-place', 'B-organization', 'O'],\n  ['12', '13', '14', '-100']),\n (15,\n  'House',\n  ['I-abstract', 'I-place', 'I-organization', 'O'],\n  ['12', '13', '14', '-100']),\n (16,\n  'of',\n  ['I-abstract', 'I-place', 'I-organization', 'O'],\n  ['12', '13', '14', '-100']),\n (17,\n  'Representatives',\n  ['I-abstract', 'L-place', 'L-organization', 'O'],\n  ['12', '13', '14', '-100']),\n (18, 'in', ['I-abstract', 'O', 'O', 'O'], ['12', '-100', '-100', '-100']),\n (19,\n  'support',\n  ['I-abstract', 'B-abstract', 'O', 'O'],\n  ['12', '3', '-100', '-100']),\n (20,\n  'of',\n  ['I-abstract', 'I-abstract', 'O', 'O'],\n  ['12', '3', '-100', '-100']),\n (21,\n  'H.',\n  ['I-abstract', 'I-abstract', 'B-abstract', 'O'],\n  ['12', '3', '4', '-100']),\n (22,\n  'R.',\n  ['I-abstract', 'I-abstract', 'I-abstract', 'O'],\n  ['12', '3', '4', '-100']),\n (23,\n  '1280',\n  ['I-abstract', 'L-abstract', 'L-abstract', 'O'],\n  ['12', '3', '4', '-100']),\n (24, ',', ['I-abstract', 'O', 'O', 'O'], ['12', '-100', '-100', '-100']),\n (25,\n  'the',\n  ['I-abstract', 'B-abstract', 'O', 'O'],\n  ['12', '4', '-100', '-100']),\n (26,\n  'George',\n  ['I-abstract', 'I-abstract', 'B-person', 'O'],\n  ['12', '4', '5', '-100']),\n (27,\n  'Floyd',\n  ['I-abstract', 'I-abstract', 'L-person', 'O'],\n  ['12', '4', '5', '-100']),\n (28,\n  'Justice',\n  ['I-abstract', 'I-abstract', 'O', 'O'],\n  ['12', '4', '-100', '-100']),\n (29,\n  'in',\n  ['I-abstract', 'I-abstract', 'O', 'O'],\n  ['12', '4', '-100', '-100']),\n (30,\n  'Policing',\n  ['I-abstract', 'I-abstract', 'U-abstract', 'O'],\n  ['12', '4', '6', '-100']),\n (31,\n  'Act',\n  ['I-abstract', 'I-abstract', 'O', 'O'],\n  ['12', '4', '-100', '-100']),\n (32,\n  'of',\n  ['I-abstract', 'I-abstract', 'O', 'O'],\n  ['12', '4', '-100', '-100']),\n (33,\n  '2021',\n  ['L-abstract', 'L-abstract', 'U-time', 'O'],\n  ['12', '4', '8', '-100']),\n (34, '.', ['O', 'O', 'O', 'O'], ['-100', '-100', '-100', '-100']),\n (35, '[SEP]', ['O', 'O', 'O', 'O'], ['-100', '-100', '-100', '-100'])]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels[sentence_id]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:44:39.133208075Z",
     "start_time": "2024-04-15T17:44:39.127042399Z"
    }
   },
   "id": "3317dd9fa01b5e23",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n 'washington',\n ',',\n 'd',\n '.',\n 'c',\n '.',\n '–',\n 'speaker',\n 'nancy',\n 'pelosi',\n 'delivered',\n 'remarks',\n 'on',\n 'the',\n 'floor',\n 'of',\n 'the',\n 'house',\n 'of',\n 'representatives',\n 'in',\n 'support',\n 'of',\n 'h',\n '.',\n 'r',\n '.',\n '1280',\n ',',\n 'the',\n 'george',\n 'floyd',\n 'justice',\n 'in',\n 'policing',\n 'act',\n 'of',\n '2021',\n '.',\n '[SEP]']"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.word_tokens[sentence_id]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:44:46.127622424Z",
     "start_time": "2024-04-15T17:44:46.119618697Z"
    }
   },
   "id": "2ec3949e59d7d049",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(10979, 60, 35)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.word_tokens), len(train_dataset.word_tokens[0]), len(train_dataset.word_tokens[-1]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:32:38.395054907Z",
     "start_time": "2024-04-15T16:32:38.392747699Z"
    }
   },
   "id": "73b986859c40cb48",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'the'"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.word_tokens[0][2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:04:05.582938014Z",
     "start_time": "2024-04-15T15:04:05.574882716Z"
    }
   },
   "id": "e448720738a1a96b",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset.labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:08:13.921961359Z",
     "start_time": "2024-04-15T15:08:13.913438729Z"
    }
   },
   "id": "432705f4e65df854",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Your input text with potentially long sentences\n",
    "input_text = \"\"\"\n",
    "So it's Shawntas Way here today, and today I'm going to be talking to you guys about number one.\n",
    "\"\"\"\n",
    "\n",
    "# Split the input text into sentences\n",
    "sentences = sent_tokenize(input_text)\n",
    "# Maximum sequence length supported by the model\n",
    "max_sequence_length = 512\n",
    "\n",
    "# Check the length of each tokenized sentence\n",
    "for sentence in sentences:\n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer(sentence, truncation=True, max_length=max_sequence_length, return_overflowing_tokens=True)\n",
    "    break\n",
    "    \n",
    "#tokenizer.convert_ids_to_tokens(tokens['input_ids'])\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab533f3538c896ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '27-28'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[85], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m labels_split \u001B[38;5;241m=\u001B[39m word\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m new_sentence_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(labels_split[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m----> 9\u001B[0m word_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlabels_split\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m word \u001B[38;5;241m=\u001B[39m labels_split[\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m     11\u001B[0m entities \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: '27-28'"
     ]
    }
   ],
   "source": [
    "labels_file_name = '../datasets/gum_parsed/labels/81.txt'\n",
    "cur_sentence_id = 1\n",
    "sentence_labels = []\n",
    "labels = []\n",
    "with open(labels_file_name, 'r', encoding='utf-8') as file_lbl:    \n",
    "    for word in file_lbl:\n",
    "        labels_split = word.strip().split('\\t')\n",
    "        new_sentence_id = int(labels_split[0])\n",
    "        word_id = int(labels_split[1])\n",
    "        word = labels_split[2]\n",
    "        entities = []\n",
    "        corefs = []\n",
    "        for i in range(7, len(labels_split)):\n",
    "            if i%2 > 0:\n",
    "                corefs.append(labels_split[i])\n",
    "            else:\n",
    "                entities.append(labels_split[i])\n",
    "                \n",
    "        if new_sentence_id != cur_sentence_id:\n",
    "            labels.append(sentence_labels)\n",
    "            sentence_labels = []\n",
    "            cur_sentence_id = new_sentence_id\n",
    "        \n",
    "        sentence_labels.append((word_id, word, entities, corefs))\n",
    "\n",
    "print(sentence_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:22:41.061929583Z",
     "start_time": "2024-04-15T15:22:41.014855062Z"
    }
   },
   "id": "addd157e522e2116",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sentence_data_collate_fn(batch):\n",
    "    text_mask = []\n",
    "    sentence_mask = []\n",
    "    sentence_length = []\n",
    "    \n",
    "    token_ids = []\n",
    "    token_mask = []    \n",
    "    word_ids = []\n",
    "    \n",
    "    word_char_ids = []\n",
    "    word_lengths = []\n",
    "    \n",
    "    max_sentence_length = 0\n",
    "    max_tokens_count = 0\n",
    "    \n",
    "    for sentence in batch:\n",
    "        if sentence['sentence_length'] > max_sentence_length:\n",
    "            max_sentence_length = sentence['sentence_length']\n",
    "        if len(sentence['token_ids']) > max_tokens_count:\n",
    "            max_tokens_count = len(sentence['token_ids'])      \n",
    "        sentence_length.append(sentence['sentence_length'])\n",
    "        text_mask.append(sentence['text_mask'])\n",
    "        sentence_mask.append(sentence['sentence_mask'])        \n",
    "    \n",
    "    for i, sentence in enumerate(batch):\n",
    "        missing_sentence_length = max_sentence_length - sentence['sentence_length']\n",
    "        missing_tokens_count = max_tokens_count - len(sentence['token_ids'])\n",
    "        token_ids.append(sentence['token_ids'] + [0]*missing_tokens_count)\n",
    "        word_ids.append(sentence['word_ids'] + [-1]*missing_tokens_count)\n",
    "        token_mask.append([1]*len(sentence['token_ids']) + [0]*missing_tokens_count)\n",
    "\n",
    "        padded_chars = sentence['word_char_ids'] + [[0]*MAX_TOKEN_LENGTH]*missing_sentence_length\n",
    "        word_char_ids.append(padded_chars)\n",
    "        word_lengths.append(sentence['word_lengths'] + [1]*missing_sentence_length)\n",
    "\n",
    "    return {\n",
    "                'token_ids': torch.tensor(token_ids), \n",
    "                'token_mask':  torch.tensor(token_mask),\n",
    "                'word_ids': torch.tensor(word_ids),         \n",
    "                'text_mask': torch.tensor(text_mask),\n",
    "                'sentence_mask': torch.tensor(sentence_mask),\n",
    "                'sentence_length': torch.tensor(sentence_length),\n",
    "                'word_char_ids': torch.tensor(word_char_ids),\n",
    "                'word_lengths': torch.tensor(word_lengths),\n",
    "            }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T09:04:23.328948715Z",
     "start_time": "2024-04-11T09:04:23.318595685Z"
    }
   },
   "id": "6e732829d51346a5",
   "execution_count": 1067
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class WordBertEmbeddingModel(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', pretrain=False, average_hidden_states=False):        \n",
    "        super(WordBertEmbeddingModel, self).__init__()\n",
    "        self.average_hidden_states = average_hidden_states\n",
    "        self.model = BertModel.from_pretrained(bert_model_name)   \n",
    "        self.embeddings_dim = self.model.config.hidden_size\n",
    "        \n",
    "        if not pretrain:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False  \n",
    "    \n",
    "               \n",
    "    def __get_mean_embeddings_for_words(self, word_ids, token_embeddings):\n",
    "        max_words_count = torch.max(batch['sentence_length']).item()\n",
    "        embeddings = []\n",
    "        for sentence, sentence_embed in zip(word_ids, token_embeddings):\n",
    "            prev_id = -1\n",
    "            sentence_embeddings = []\n",
    "            prev_embedding = None\n",
    "            collected_embeddings = []\n",
    "            for word_id, token_embed in zip(sentence, sentence_embed):\n",
    "                if word_id == -1:\n",
    "                    break\n",
    "                    \n",
    "                if prev_id == -1:\n",
    "                    prev_id = word_id\n",
    "                    prev_embedding = token_embed\n",
    "                    continue\n",
    "                    \n",
    "                if word_id == prev_id:\n",
    "                    collected_embeddings.append(prev_embedding)                    \n",
    "                else:\n",
    "                    if len(collected_embeddings) > 0:\n",
    "                        collected_embeddings.append(prev_embedding)\n",
    "                        sentence_embeddings.append(torch.tensor(np.mean(collected_embeddings, axis=0)))\n",
    "                        collected_embeddings = []\n",
    "                    else:\n",
    "                        sentence_embeddings.append(prev_embedding)\n",
    "                    prev_id = word_id                    \n",
    "                prev_embedding = token_embed\n",
    "            \n",
    "            if len(collected_embeddings) > 0:\n",
    "                collected_embeddings.append(prev_embedding)\n",
    "                sentence_embeddings.append(torch.tensor(np.mean(collected_embeddings, axis=0)))\n",
    "            else:\n",
    "                sentence_embeddings.append(prev_embedding)          \n",
    "               \n",
    "            embeddings.append(torch.stack(sentence_embeddings))\n",
    "          \n",
    "        \n",
    "        for i, length in enumerate(batch['sentence_length']):\n",
    "            if length.item() < max_words_count:\n",
    "                embeddings[i] = torch.cat((embeddings[i], torch.zeros(max_words_count - length.item(), \n",
    "                                                                      self.embeddings_dim)), dim=0)  \n",
    "            \n",
    "        return torch.stack(embeddings)\n",
    "                    \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x = self.model(input_ids= batch['token_ids'], attention_mask=batch['token_mask'])  \n",
    "        if not self.average_hidden_states:\n",
    "            x = x['last_hidden_state']\n",
    "        else:\n",
    "            x = torch.mean(torch.stack(x.hidden_states), dim=0)\n",
    "        x = self.__get_mean_embeddings_for_words(batch['word_ids'], x)\n",
    "        return x        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T10:20:32.226600156Z",
     "start_time": "2024-04-11T10:20:32.184042087Z"
    }
   },
   "id": "d26ca4b054bdadfa",
   "execution_count": 1230
  },
  {
   "cell_type": "markdown",
   "source": [
    "Char representation per word"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10ed301d70bd86e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CharLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_dim, embedding_dim, output_dim, bidirectional=True, num_layers=1):        \n",
    "        super(CharLSTMModel, self).__init__()              \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding_layer = nn.Embedding(vocab_dim, embedding_dim, padding_idx=0)\n",
    "        self.lstm_layer = nn.LSTM(embedding_dim, output_dim // 2 if bidirectional else output_dim, \n",
    "                                  bidirectional=bidirectional, \n",
    "                                  num_layers=num_layers, batch_first=True)        \n",
    "    def forward(self, batch):\n",
    "        (batch_size, sentence_max_length, word_max_length) = batch['word_char_ids'].shape\n",
    "        x = batch['word_char_ids'].view(batch_size * sentence_max_length, word_max_length)\n",
    "        x = self.embedding_layer(x)        \n",
    "        flat_token_length = batch['word_lengths'].view(-1)\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, flat_token_length, batch_first=True, enforce_sorted=False)\n",
    "        x, _ = self.lstm_layer(x)        \n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True, total_length=word_max_length)\n",
    "        x = x.view(batch_size, sentence_max_length, -1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T07:26:28.299017531Z",
     "start_time": "2024-04-12T07:26:28.291713102Z"
    }
   },
   "id": "b9e14285e7fe007a",
   "execution_count": 1272
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ContextLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, bidirectional=True, num_layers=1,\n",
    "                 input_dropout_rate=0.5, hidden_dropout_rate=0.5, output_dropout_rate=0.5,\n",
    "                 init_hidden_to_random = True):\n",
    "        super(ContextLSTMModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.init_hidden_to_random = init_hidden_to_random\n",
    "\n",
    "        #LSTM layers\n",
    "        self.lstm_layer = nn.LSTM(input_dim, hidden_dim // 2 if bidirectional else hidden_dim, num_layers=num_layers, \n",
    "                            bidirectional=bidirectional, batch_first=True, \n",
    "                            dropout=hidden_dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        #Dropout layers for input and output\n",
    "        if input_dropout_rate and input_dropout_rate > 0:\n",
    "            self.dropout_input_layer = nn.Dropout(input_dropout_rate)\n",
    "        \n",
    "        if output_dropout_rate and output_dropout_rate > 0:\n",
    "            self.dropout_output_layer = nn.Dropout(output_dropout_rate)\n",
    "            \n",
    "        #FC layer to map the LSTM output of into output space \n",
    "        self.fc_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        if self.init_hidden_to_random:\n",
    "            return torch.randn((2 if self.bidirectional else 1) * self.num_layers, batch_size, \n",
    "                               self.hidden_dim // 2 if self.bidirectional else self.hidden_dim)\n",
    "        else:\n",
    "            return torch.zeros((2 if self.bidirectional else 1) * self.num_layers, batch_size, \n",
    "                               self.hidden_dim // 2 if self.bidirectional else self.hidden_dim)\n",
    "    \n",
    "    def forward(self, sentences, sentence_lengths):\n",
    "        (batch_size, sentence_max_length, _) = sentences.shape\n",
    "        \n",
    "        hidden = self.init_hidden_state(batch_size)\n",
    "        state = self.init_hidden_state(batch_size)        \n",
    "        \n",
    "        x = sentences\n",
    "        if self.dropout_input_layer:\n",
    "            x = self.dropout_input_layer(x)\n",
    "\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, sentence_lengths, batch_first=True, enforce_sorted=False)\n",
    "        x, (self.hidden, self.state) = self.lstm_layer(x, (hidden, state))\n",
    "        #x, _ = self.lstm_layer(x)\n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True, total_length=sentence_max_length)\n",
    "        \n",
    "        if self.dropout_output_layer:\n",
    "            x = self.dropout_output_layer(x)            \n",
    "        x = self.fc_layer(x)        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T07:53:33.657118724Z",
     "start_time": "2024-04-12T07:53:33.651614214Z"
    }
   },
   "id": "e7f7f30d8893241f",
   "execution_count": 1314
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CRFModel(nn.Module):\n",
    "    def __init__(self, labels_len):\n",
    "        super(CRFModel, self).__init__()    \n",
    "        self.labels_len = labels_len\n",
    "        self.transitions = nn.Parameter(torch.empty(self.labels_len, self.labels_len))\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # initialize transitions from a random uniform distribution between -0.1 and 0.1\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
    "        # no transitions allowed to the beginning or from the end of sentence, from or to padding\n",
    "        self.transitions.data[:, START_SENTENCE_TOKEN_ID] = -10000.0\n",
    "        self.transitions.data[SEP_SENTENCE_TOKEN_ID, :] = -10000.0\n",
    "        self.transitions.data[PAD_TOKEN_ID, :] = -10000.0\n",
    "        self.transitions.data[:, PAD_TOKEN_ID] = -10000.0\n",
    "        # or we are already in a pad position\n",
    "        self.transitions.data[PAD_TOKEN_ID, SEP_SENTENCE_TOKEN_ID] = 0.0\n",
    "        self.transitions.data[PAD_TOKEN_ID, PAD_TOKEN_ID] = 0.0\n",
    "        \n",
    "    def forward(self, sentences, labels, words_mask=None):\n",
    "        \"\"\"Compute the negative log-likelihood. See `log_likelihood` method.\"\"\"\n",
    "        neg_likelihood = -self.log_likelihood(sentences, labels, words_mask=words_mask)\n",
    "        return neg_likelihood\n",
    "\n",
    "    def log_likelihood(self, sentences, labels, words_mask=None): \n",
    "        if words_mask is None:\n",
    "            words_mask = torch.ones(sentences.shape[:2], dtype=torch.float)\n",
    "    \n",
    "        scores = self._compute_scores(sentences, labels, words_mask=words_mask)\n",
    "        partition = self._compute_log_partition(sentences, words_mask=words_mask)\n",
    "        return torch.sum(scores - partition)\n",
    "\n",
    "    def _compute_scores(self, sentences, labels, words_mask):\n",
    "        batch_size, seq_length = labels.shape\n",
    "        scores = torch.zeros(batch_size)\n",
    "    \n",
    "        # save first and last tags to be used later\n",
    "        first_tags = labels[:, 0]\n",
    "        last_valid_idx = words_mask.int().sum(1) - 1\n",
    "        last_tags = labels.gather(1, last_valid_idx.unsqueeze(1)).squeeze()\n",
    "    \n",
    "        # add the transition from BOS to the first tags for each batch\n",
    "        t_scores = self.transitions[self.BOS_TAG_ID, first_tags]\n",
    "    \n",
    "        # add the [unary] emission scores for the first tags for each batch\n",
    "        # for all batches, the first word, see the correspondent emissions\n",
    "        # for the first tags (which is a list of ids):\n",
    "        # emissions[:, 0, [tag_1, tag_2, ..., tag_nblabels]]\n",
    "        e_scores = sentences[:, 0].gather(1, first_tags.unsqueeze(1)).squeeze()\n",
    "    \n",
    "        # the scores for a word is just the sum of both scores\n",
    "        scores += e_scores + t_scores\n",
    "    \n",
    "        # now lets do this for each remaining word\n",
    "        for i in range(1, seq_length):\n",
    "    \n",
    "            # we could: iterate over batches, check if we reached a mask symbol\n",
    "            # and stop the iteration, but vecotrizing is faster due to gpu,\n",
    "            # so instead we perform an element-wise multiplication\n",
    "            is_valid = words_mask[:, i]\n",
    "    \n",
    "            previous_tags = labels[:, i - 1]\n",
    "            current_tags = labels[:, i]\n",
    "    \n",
    "            # calculate emission and transition scores as we did before\n",
    "            e_scores = sentences[:, i].gather(1, current_tags.unsqueeze(1)).squeeze()\n",
    "            t_scores = self.transitions[previous_tags, current_tags]\n",
    "    \n",
    "            # apply the mask\n",
    "            e_scores = e_scores * is_valid\n",
    "            t_scores = t_scores * is_valid\n",
    "    \n",
    "            scores += e_scores + t_scores\n",
    "    \n",
    "        # add the transition from the end tag to the EOS tag for each batch\n",
    "        scores += self.transitions[last_tags, self.EOS_TAG_ID]\n",
    "    \n",
    "        return scores\n",
    "\n",
    "    def _compute_log_partition(self, sentences, words_mask):\n",
    "        \"\"\"Compute the partition function in log-space using the forward-algorithm.\n",
    "        Args:\n",
    "            emissions (torch.Tensor): (batch_size, seq_len, nb_labels)\n",
    "            mask (Torch.FloatTensor): (batch_size, seq_len)\n",
    "        Returns:\n",
    "            torch.Tensor: the partition scores for each batch.\n",
    "                Shape of (batch_size,)\n",
    "        \"\"\"\n",
    "        batch_size, seq_length, nb_labels = sentences.shape\n",
    "    \n",
    "        # in the first iteration, BOS will have all the scores\n",
    "        alphas = self.transitions[self.BOS_TAG_ID, :].unsqueeze(0) + sentences[:, 0]\n",
    "    \n",
    "        for i in range(1, seq_length):\n",
    "            alpha_t = []\n",
    "    \n",
    "            for tag in range(nb_labels):\n",
    "    \n",
    "                # get the emission for the current tag\n",
    "                e_scores = sentences[:, i, tag]\n",
    "    \n",
    "                # broadcast emission to all labels\n",
    "                # since it will be the same for all previous tags\n",
    "                # (bs, nb_labels)\n",
    "                e_scores = e_scores.unsqueeze(1)\n",
    "    \n",
    "                # transitions from something to our tag\n",
    "                t_scores = self.transitions[:, tag]\n",
    "    \n",
    "                # broadcast the transition scores to all batches\n",
    "                # (bs, nb_labels)\n",
    "                t_scores = t_scores.unsqueeze(0)\n",
    "    \n",
    "                # combine current scores with previous alphas\n",
    "                # since alphas are in log space (see logsumexp below),\n",
    "                # we add them instead of multiplying\n",
    "                scores = e_scores + t_scores + alphas\n",
    "    \n",
    "                # add the new alphas for the current tag\n",
    "                alpha_t.append(torch.logsumexp(scores, dim=1))\n",
    "    \n",
    "            # create a torch matrix from alpha_t\n",
    "            # (bs, nb_labels)\n",
    "            new_alphas = torch.stack(alpha_t).t()\n",
    "    \n",
    "            # set alphas if the mask is valid, otherwise keep the current values\n",
    "            is_valid = words_mask[:, i].unsqueeze(-1)\n",
    "            alphas = is_valid * new_alphas + (1 - is_valid) * alphas\n",
    "    \n",
    "        # add the scores for the final transition\n",
    "        last_transition = self.transitions[:, self.EOS_TAG_ID]\n",
    "        end_scores = alphas + last_transition.unsqueeze(0)\n",
    "    \n",
    "        # return a *log* of sums of exps\n",
    "        return torch.logsumexp(end_scores, dim=1)\n",
    "\n",
    "    def _viterbi_decode(self, sentences, words_mask):\n",
    "        \"\"\"Compute the viterbi algorithm to find the most probable sequence of labels\n",
    "        given a sequence of emissions.\n",
    "\n",
    "        Args:\n",
    "            emissions (torch.Tensor): (batch_size, seq_len, nb_labels)\n",
    "            mask (Torch.FloatTensor): (batch_size, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: the viterbi score for the for each batch.\n",
    "                Shape of (batch_size,)\n",
    "            list of lists of ints: the best viterbi sequence of labels for each batch\n",
    "        \"\"\"\n",
    "        batch_size, seq_length, nb_labels = sentences.shape\n",
    "\n",
    "        # in the first iteration, BOS will have all the scores and then, the max\n",
    "        alphas = self.transitions[self.BOS_TAG_ID, :].unsqueeze(0) + sentences[:, 0]\n",
    "\n",
    "        backpointers = []\n",
    "\n",
    "        for i in range(1, seq_length):\n",
    "            alpha_t = []\n",
    "            backpointers_t = []\n",
    "\n",
    "            for tag in range(nb_labels):\n",
    "\n",
    "                # get the emission for the current tag and broadcast to all labels\n",
    "                e_scores = sentences[:, i, tag]\n",
    "                e_scores = e_scores.unsqueeze(1)\n",
    "\n",
    "                # transitions from something to our tag and broadcast to all batches\n",
    "                t_scores = self.transitions[:, tag]\n",
    "                t_scores = t_scores.unsqueeze(0)\n",
    "\n",
    "                # combine current scores with previous alphas\n",
    "                scores = e_scores + t_scores + alphas\n",
    "\n",
    "                # so far is exactly like the forward algorithm,\n",
    "                # but now, instead of calculating the logsumexp,\n",
    "                # we will find the highest score and the tag associated with it\n",
    "                max_score, max_score_tag = torch.max(scores, dim=-1)\n",
    "\n",
    "                # add the max score for the current tag\n",
    "                alpha_t.append(max_score)\n",
    "\n",
    "                # add the max_score_tag for our list of backpointers\n",
    "                backpointers_t.append(max_score_tag)\n",
    "\n",
    "            # create a torch matrix from alpha_t\n",
    "            # (bs, nb_labels)\n",
    "            new_alphas = torch.stack(alpha_t).t()\n",
    "\n",
    "            # set alphas if the mask is valid, otherwise keep the current values\n",
    "            is_valid = words_mask[:, i].unsqueeze(-1)\n",
    "            alphas = is_valid * new_alphas + (1 - is_valid) * alphas\n",
    "\n",
    "            # append the new backpointers\n",
    "            backpointers.append(backpointers_t)\n",
    "\n",
    "        # add the scores for the final transition\n",
    "        last_transition = self.transitions[:, self.EOS_TAG_ID]\n",
    "        end_scores = alphas + last_transition.unsqueeze(0)\n",
    "\n",
    "        # get the final most probable score and the final most probable tag\n",
    "        max_final_scores, max_final_tags = torch.max(end_scores, dim=1)\n",
    "\n",
    "        # find the best sequence of labels for each sample in the batch\n",
    "        best_sequences = []\n",
    "        emission_lengths = words_mask.int().sum(dim=1)\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # recover the original sentence length for the i-th sample in the batch\n",
    "            sample_length = emission_lengths[i].item()\n",
    "\n",
    "            # recover the max tag for the last timestep\n",
    "            sample_final_tag = max_final_tags[i].item()\n",
    "\n",
    "            # limit the backpointers until the last but one\n",
    "            # since the last corresponds to the sample_final_tag\n",
    "            sample_backpointers = backpointers[: sample_length - 1]\n",
    "\n",
    "            # follow the backpointers to build the sequence of labels\n",
    "            sample_path = self._find_best_path(i, sample_final_tag, sample_backpointers)\n",
    "\n",
    "            # add this path to the list of best sequences\n",
    "            best_sequences.append(sample_path)\n",
    "\n",
    "        return max_final_scores, best_sequences\n",
    "\n",
    "    def _find_best_path(self, sample_id, best_tag, backpointers):\n",
    "        \"\"\"Auxiliary function to find the best path sequence for a specific sample.\n",
    "\n",
    "            Args:\n",
    "                sample_id (int): sample index in the range [0, batch_size)\n",
    "                best_tag (int): tag which maximizes the final score\n",
    "                backpointers (list of lists of tensors): list of pointers with\n",
    "                shape (seq_len_i-1, nb_labels, batch_size) where seq_len_i\n",
    "                represents the length of the ith sample in the batch\n",
    "\n",
    "            Returns:\n",
    "                list of ints: a list of tag indexes representing the bast path\n",
    "        \"\"\"\n",
    "\n",
    "        # add the final best_tag to our best path\n",
    "        best_path = [best_tag]\n",
    "\n",
    "        # traverse the backpointers in backwards\n",
    "        for backpointers_t in reversed(backpointers):\n",
    "\n",
    "            # recover the best_tag at this timestep\n",
    "            best_tag = backpointers_t[best_tag][sample_id].item()\n",
    "\n",
    "            # append to the beginning of the list so we don't need to reverse it later\n",
    "            best_path.insert(0, best_tag)\n",
    "\n",
    "        return best_path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a54b4c73b7ba73"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "file_dir = 'data_exp/texts'  # Directory containing text files\n",
    "#labels_dir = 'data_exp/labels'  \n",
    "BATCH_SIZE = 2\n",
    "CHAR_EMBEDDING_DIM = 10\n",
    "CHAR_LSTM_OUTPUT = 20\n",
    "CONTEXT_HIDDEN_DIM = 20\n",
    "NUM_LABELS = 11\n",
    "MAX_TOKEN_LENGTH = 15\n",
    "\n",
    "train_dataset = MultiSentenceDataset(file_dir, \n",
    "                                     bert_model_name=bert_model_name, \n",
    "                                     uncased=True)\n",
    "\n",
    "char_vocab_dim = train_dataset.chars_vocab_dim\n",
    "\n",
    "word_model = WordBertEmbeddingModel(bert_model_name=bert_model_name)\n",
    "word_embedding_dim = word_model.embeddings_dim\n",
    "\n",
    "char_model = CharLSTMModel(vocab_dim=char_vocab_dim,\n",
    "                           embedding_dim=CHAR_EMBEDDING_DIM,\n",
    "                           output_dim=CHAR_LSTM_OUTPUT,                           \n",
    "                           )\n",
    "\n",
    "context_model = ContextLSTMModel(input_dim=word_model.embeddings_dim + CHAR_LSTM_OUTPUT*MAX_TOKEN_LENGTH, \n",
    "                                 hidden_dim=CONTEXT_HIDDEN_DIM,\n",
    "                                 output_dim=NUM_LABELS)\n",
    "\n",
    "crf_model = CRF()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T07:53:39.267859478Z",
     "start_time": "2024-04-12T07:53:38.752053859Z"
    }
   },
   "id": "ccaa3012835d9fe9",
   "execution_count": 1315
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0\n",
      "Token IDs Shape: torch.Size([2, 9])\n",
      "Token Attention Mask Shape: torch.Size([2, 9])\n",
      "Word IDs Shape: torch.Size([2, 9])\n",
      "Text mask Shape: torch.Size([2])\n",
      "Sentence mask Shape: torch.Size([2])\n",
      "Sentence length Shape: torch.Size([2])\n",
      "Word chars Shape: torch.Size([2, 9, 15])\n",
      "Word lengths Shape: torch.Size([2, 9])\n",
      "Embedded IDs Shape: torch.Size([2, 9, 768])\n",
      "char_embeddings Shape: torch.Size([2, 9, 300])\n",
      "word_char_embeddings Shape: torch.Size([2, 9, 1068])\n",
      "context_embeddings Shape: torch.Size([2, 9, 11])\n",
      "Index:  1\n",
      "Token IDs Shape: torch.Size([2, 10])\n",
      "Token Attention Mask Shape: torch.Size([2, 10])\n",
      "Word IDs Shape: torch.Size([2, 10])\n",
      "Text mask Shape: torch.Size([2])\n",
      "Sentence mask Shape: torch.Size([2])\n",
      "Sentence length Shape: torch.Size([2])\n",
      "Word chars Shape: torch.Size([2, 10, 15])\n",
      "Word lengths Shape: torch.Size([2, 10])\n",
      "Embedded IDs Shape: torch.Size([2, 10, 768])\n",
      "char_embeddings Shape: torch.Size([2, 10, 300])\n",
      "word_char_embeddings Shape: torch.Size([2, 10, 1068])\n",
      "context_embeddings Shape: torch.Size([2, 10, 11])\n",
      "Index:  2\n",
      "Token IDs Shape: torch.Size([2, 14])\n",
      "Token Attention Mask Shape: torch.Size([2, 14])\n",
      "Word IDs Shape: torch.Size([2, 14])\n",
      "Text mask Shape: torch.Size([2])\n",
      "Sentence mask Shape: torch.Size([2])\n",
      "Sentence length Shape: torch.Size([2])\n",
      "Word chars Shape: torch.Size([2, 10, 15])\n",
      "Word lengths Shape: torch.Size([2, 10])\n",
      "Embedded IDs Shape: torch.Size([2, 10, 768])\n",
      "char_embeddings Shape: torch.Size([2, 10, 300])\n",
      "word_char_embeddings Shape: torch.Size([2, 10, 1068])\n",
      "context_embeddings Shape: torch.Size([2, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "seq_sampler = torch.utils.data.sampler.SequentialSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                              sampler=seq_sampler, collate_fn=sentence_data_collate_fn)\n",
    "\n",
    "for index, batch in enumerate(train_dataloader):\n",
    "    print('Index: ', index)\n",
    "    # print(\"Token IDs Shape:\", batch['token_ids'].shape)\n",
    "    # print(\"Token Attention Mask Shape:\", batch['token_mask'].shape)\n",
    "    # print(\"Word IDs Shape:\", batch['word_ids'].shape)\n",
    "    # print(\"Text mask Shape:\", batch['text_mask'].shape)\n",
    "    # print(\"Sentence mask Shape:\", batch['sentence_mask'].shape)    \n",
    "    # print(\"Sentence length Shape:\", batch['sentence_length'].shape)    \n",
    "    # print(\"Word chars Shape:\", batch['word_char_ids'].shape)\n",
    "    # print(\"Word lengths Shape:\", batch['word_lengths'].shape)\n",
    "\n",
    "    word_embeddings = word_model(batch)          \n",
    "    #print(\"Embedded IDs Shape:\", word_embeddings.shape)\n",
    "    \n",
    "    char_embeddings = char_model(batch)\n",
    "    #print(\"char_embeddings Shape:\", char_embeddings.shape)\n",
    "    \n",
    "    word_char_embeddings = torch.cat((word_embeddings, char_embeddings), 2)\n",
    "    #print(\"word_char_embeddings Shape:\", word_char_embeddings.shape)\n",
    "    \n",
    "    context_embeddings = context_model(word_char_embeddings, batch['sentence_length'])\n",
    "    print(\"context_embeddings Shape:\", context_embeddings.shape)\n",
    "    \n",
    "    if 'labels' in batch:\n",
    "        labels = batch['labels']\n",
    "        print(\"Labels Shape:\", labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T07:53:41.251813406Z",
     "start_time": "2024-04-12T07:53:41.157927458Z"
    }
   },
   "id": "9e2e8a3c05ccf934",
   "execution_count": 1316
  },
  {
   "cell_type": "markdown",
   "source": [
    "emissions (output of a BiLSTM or other sequence encoder) \n",
    "https://towardsdatascience.com/implementing-a-linear-chain-conditional-random-field-crf-in-pytorch-16b0b9c4b4ea\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "765b989e080929b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BiLISTM_CRF(nn.Module):\n",
    "    def __init__(self, \n",
    "                 tag_to_ix, hidden_dim,\n",
    "                 vocab_size, word_embedding_dim, pre_word_embeds=None,                  \n",
    "                 char_to_ix=None, char_out_dimension=25, char_embedding_dim=25, char_num_layers=1,\n",
    "                 use_gpu=False, use_char=True, use_crf=True,\n",
    "                 dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        Input parameters:\n",
    "                \n",
    "                vocab_size= Size of vocabulary (int)\n",
    "                tag_to_ix = Dictionary that maps NER tags to indices\n",
    "                word_embedding_dim = Dimension of word embeddings (int)\n",
    "                hidden_dim = The hidden dimension of the LSTM layer (int)\n",
    "                char_to_ix = Dictionary that maps characters to indices\n",
    "                pre_word_embeds = Numpy array which provides mapping from word embeddings to word indices\n",
    "                char_out_dimension = Output dimension from the encoder for character\n",
    "                char_embedding_dim = Dimension of the character embeddings\n",
    "                use_gpu = defines availability of GPU, \n",
    "                    when True: CUDA function calls are made\n",
    "                    else: Normal CPU function calls are made\n",
    "                use_crf = parameter which decides if you want to use the CRF layer for output decoding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_gpu = use_gpu\n",
    "        #self.word_embedding_dim = word_embedding_dim\n",
    "        #self.hidden_dim = hidden_dim\n",
    "        #self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.use_crf = use_crf\n",
    "        self.use_char = use_char\n",
    "        self.char_out_dimension = char_out_dimension\n",
    "        \n",
    "        if self.use_char:\n",
    "            self.char_embeds = nn.Embedding(len(self.char_to_ix), char_embedding_dim)            \n",
    "            self.char_lstm = nn.LSTM(char_embedding_dim, char_out_dimension, num_layers=char_num_layers, bidirectional=True)\n",
    "    \n",
    "        self.word_embeds = nn.Embedding(vocab_size, word_embedding_dim)\n",
    "        \n",
    "         ## ? get existent ??\n",
    "        if pre_word_embeds is not None:\n",
    "            #Initializes the word embeddings with pretrained word embeddings\n",
    "            self.pre_word_embeds = True\n",
    "            self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "        else:\n",
    "            self.pre_word_embeds = False\n",
    "        \n",
    "        #Drop out layer \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        #BiLSTM for concatenated embeddings layer \n",
    "        self.lstm = nn.LSTM(word_embedding_dim + (char_out_dimension * 2 if use_char else 0), \n",
    "                            hidden_dim, bidirectional=True)\n",
    "        \n",
    "        # Linear layer to maps the output of the biLSTM into tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, len(tag_to_ix))\n",
    "        \n",
    "        # Initialize the matrix of transition parameters between entities\n",
    "        if self.use_crf:            \n",
    "            self.transitions = nn.Parameter(torch.zeros(len(tag_to_ix), len(tag_to_ix)))            \n",
    "            # Never transfer to the start tag or from the end tag\n",
    "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "            self.transitions.data[:, tag_to_ix[END_TAG]] = -10000\n",
    "\n",
    "    \n",
    "    def _get_lstm_features(self, sentence, characters, characters_lengths, d):\n",
    "        \n",
    "        #get characters embeddings\n",
    "        chars_embeds = self.char_embeds(characters).transpose(0, 1)\n",
    "        #prepaire for LSTM to avoid padding\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, characters_lengths)\n",
    "        \n",
    "        lstm_out, _ = self.char_lstm(packed)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "            \n",
    "        chars_embeds_temp = torch.zeros((outputs.size(0), outputs.size(2)), dtype=torch.float32)\n",
    "            \n",
    "        if self.use_gpu:\n",
    "            chars_embeds_temp = chars_embeds_temp.cuda()\n",
    "        # cut paddings             \n",
    "        for i, index in enumerate(output_lengths):\n",
    "            chars_embeds_temp[i] = torch.cat((outputs[i, index-1, :self.char_lstm_dim], outputs[i, 0, self.char_lstm_dim:]))\n",
    "        \n",
    "        chars_embeds = chars_embeds_temp.clone()\n",
    "        \n",
    "        for i in range(chars_embeds.size(0)):\n",
    "            chars_embeds[d[i]] = chars_embeds_temp[i]\n",
    "\n",
    "    \n",
    "        ## Loading word embeddings\n",
    "        embeds = self.word_embeds(sentence)\n",
    "    \n",
    "        ## We concatenate the word embeddings and the character level representation\n",
    "        ## to create unified representation for each word\n",
    "        embeds = torch.cat((embeds, chars_embeds), 1)\n",
    "    \n",
    "        embeds = embeds.unsqueeze(1)\n",
    "    \n",
    "        ## Dropout on the unified embeddings\n",
    "        embeds = self.dropout(embeds)\n",
    "    \n",
    "        ## Word lstm\n",
    "        ## Takes words as input and generates a output at each step\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "    \n",
    "        ## Reshaping the outputs from the lstm layer\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim*2)\n",
    "    \n",
    "        ## Dropout on the lstm output\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "    \n",
    "        ## Linear layer converts the ouput vectors to tag space\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        \n",
    "        return lstm_feats\n",
    "    \n",
    "    def viterbi_algo(self, feats):\n",
    "        '''\n",
    "        In this function, we implement the viterbi algorithm explained above.\n",
    "        A Dynamic programming based approach to find the best tag sequence\n",
    "        '''\n",
    "        backpointers = []\n",
    "        # analogous to forward\n",
    "        \n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "        \n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        if self.use_gpu:\n",
    "            forward_var = forward_var.cuda()\n",
    "        for feat in feats:\n",
    "            next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n",
    "            _, bptrs_t = torch.max(next_tag_var, dim=1)\n",
    "            bptrs_t = bptrs_t.squeeze().data.cpu().numpy() # holds the backpointers for this step\n",
    "            next_tag_var = next_tag_var.data.cpu().numpy() \n",
    "            viterbivars_t = next_tag_var[range(len(bptrs_t)), bptrs_t] # holds the viterbi variables for this step\n",
    "            viterbivars_t = Variable(torch.FloatTensor(viterbivars_t))\n",
    "            if self.use_gpu:\n",
    "                viterbivars_t = viterbivars_t.cuda()\n",
    "                \n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = viterbivars_t + feat\n",
    "            backpointers.append(bptrs_t)\n",
    "    \n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
    "        terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
    "        best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
    "        path_score = terminal_var[best_tag_id]\n",
    "        \n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "            \n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG] # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "    \n",
    "    def forward(self, sentence, chars, chars2_length, d):\n",
    "        feats = self._get_lstm_features(sentence, chars, chars2_length, d)\n",
    "        \n",
    "        # Find the best path, given the features.\n",
    "        if self.use_crf:\n",
    "            score, tag_seq = self.viterbi_decode(feats)\n",
    "        else:\n",
    "            score, tag_seq = torch.max(feats, 1)\n",
    "            tag_seq = list(tag_seq.cpu().data)\n",
    "    \n",
    "        return score, tag_seq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:15.887893755Z",
     "start_time": "2024-04-05T08:24:15.847075569Z"
    }
   },
   "id": "e674c02dbb1bd230",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
